{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b377b8",
   "metadata": {},
   "source": [
    "## ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b4c321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Gender_encoded', 'Geography_France', 'Geography_Spain']\n",
      "X shape: (5, 11), y shape: (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\ANN Classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,881</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,881\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,881</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,881\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 0.5783 - precision: 1.0000 - recall: 0.6667 - val_accuracy: 0.0000e+00 - val_loss: 0.6995 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5000 - loss: 0.7688 - precision: 0.6667 - recall: 0.6667 - val_accuracy: 1.0000 - val_loss: 0.6927 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7500 - loss: 0.5517 - precision: 0.7500 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.6831 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5000 - loss: 0.5145 - precision: 0.6667 - recall: 0.6667 - val_accuracy: 1.0000 - val_loss: 0.6741 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.5000 - loss: 0.7030 - precision: 0.6667 - recall: 0.6667 - val_accuracy: 1.0000 - val_loss: 0.6668 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7500 - loss: 0.5673 - precision: 0.7500 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.6593 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7500 - loss: 0.6217 - precision: 0.7500 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.6510 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.4413 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.6426 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7500 - loss: 0.4960 - precision: 0.7500 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.6338 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7500 - loss: 0.4743 - precision: 1.0000 - recall: 0.6667 - val_accuracy: 1.0000 - val_loss: 0.6257 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7500 - loss: 0.5120 - precision: 0.7500 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.6175 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7500 - loss: 0.5618 - precision: 0.7500 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.6094 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.4071 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5998 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5000 - loss: 0.6168 - precision: 0.6667 - recall: 0.6667 - val_accuracy: 1.0000 - val_loss: 0.5905 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.4228 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5818 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.3909 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5735 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7500 - loss: 0.5181 - precision: 0.7500 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5652 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.3434 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5576 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.4192 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5498 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.3596 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5429 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.2526 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5362 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.3395 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5302 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.3610 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5244 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.3776 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5189 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.2712 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5137 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.3375 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5088 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.3304 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.5043 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.1823 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4998 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.3827 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4946 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.3214 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4892 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.2239 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4837 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1799 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4785 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.2407 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4734 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1658 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4682 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1947 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4633 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1874 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4588 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.2717 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4546 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.1921 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4507 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1909 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4466 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.2012 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4426 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1781 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4388 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1806 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4349 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1134 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4307 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.1522 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4266 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1713 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4226 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.2094 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4186 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1847 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4150 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.1676 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4115 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.2250 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4080 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1383 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4045 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.2293 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.4010 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0708 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3974 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1656 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3939 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.1414 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3905 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0857 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3872 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0945 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3838 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1347 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3805 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1341 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3775 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0684 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3746 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0775 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3720 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0888 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3692 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0849 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3665 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1020 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3637 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0620 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3608 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0584 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3582 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0630 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3558 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1322 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3533 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1333 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3509 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0434 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3487 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1464 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3469 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0823 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3454 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0868 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3437 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0777 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3422 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0609 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3407 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0313 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3392 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0646 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3374 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0501 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3355 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0527 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3338 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0517 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3325 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0869 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3313 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0269 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3302 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0540 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3293 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0792 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3285 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.1238 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3281 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0326 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3280 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0712 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3274 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0757 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3264 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0372 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3254 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0303 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3245 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0170 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3237 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0287 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3229 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0467 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3218 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0202 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3207 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0502 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3194 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0392 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3185 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0388 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3180 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0367 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3170 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.0104 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3161 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0703 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3162 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0260 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.3163 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Restoring model weights from the end of the best epoch: 98.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,645</span> (33.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,645\u001b[0m (33.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,881</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,881\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,764</span> (22.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,764\u001b[0m (22.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import regularizers\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "## Load Data sets\n",
    "data = pd.read_excel(\"Churn_Modelling_sample.csv.xlsx\")\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "\n",
    "## Preprocess the data\n",
    "# Drop the irrelevant columns\n",
    "data = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)\n",
    "\n",
    "# Fix: Check if Gender column exists and encode properly\n",
    "if \"Gender\" in data.columns:\n",
    "    label_encoder_gender = LabelEncoder()\n",
    "    data[\"Gender_encoded\"] = label_encoder_gender.fit_transform(data[\"Gender\"])\n",
    "    data = data.drop(\"Gender\", axis=1)\n",
    "else:\n",
    "    print(\"Gender column not found, skipping encoding\")\n",
    "\n",
    "# OneHot encoder for Geography\n",
    "if \"Geography\" in data.columns:\n",
    "    onehot_encoder_geo = OneHotEncoder(sparse_output=False)  # Fix: sparse=False deprecated\n",
    "    geo_encoded = onehot_encoder_geo.fit_transform(data[[\"Geography\"]])\n",
    "    geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out([\"Geography\"]))\n",
    "    data = pd.concat([data.drop(\"Geography\", axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "# Save the encoders\n",
    "with open(\"label_encoder_gender.pkl\", \"wb\") as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open(\"onehot_encoder_geo.pkl\", \"wb\") as file:  # Fix: correct filename\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "# Divide the datasets into dependent and independent features\n",
    "X = data.drop(\"Exited\", axis=1)  ## removed this column because no need of scaling\n",
    "y = data[\"Exited\"] ## to avoid scaling\n",
    "\n",
    "# Remove any remaining non-numeric columns\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"Feature columns: {X.columns.tolist()}\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler\n",
    "with open(\"scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "## Build the ANN model with better architecture\n",
    "model = Sequential([\n",
    "    Dense(64, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", \"precision\", \"recall\"]\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "## Setup TensorBoard with proper logging\n",
    "log_dir = \"logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir, \n",
    "    histogram_freq=1,  # Log histograms every epoch\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch'\n",
    ")\n",
    "\n",
    "## Set up Early Stopping\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,  # Increased patience\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=100,  # Increased epochs\n",
    "    batch_size=32,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('churn_model.h5')  ## in Keras way\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38dac2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831d71b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d859d22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15088), started 0:00:03 ago. (Use '!kill 15088' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9c9d3b3e15434508\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9c9d3b3e15434508\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit20250815-110854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5fd63ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2afdfbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03529b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
